# Terminal AI Configuration
# Copy this file to .env and fill in your values

# ==============================================================================
# OpenAI Configuration
# ==============================================================================

# API Key (Required) - Can also be set via OPENAI_API_KEY
TERMINAL_AI_OPENAI_API_KEY=your-api-key-here
# Or use the standard OpenAI environment variable:
# OPENAI_API_KEY=your-api-key-here

# For secure API key storage, you can reference a file instead:
# TERMINAL_AI_API_KEY_FILE=/path/to/secure/api_key_file

# Model Configuration
TERMINAL_AI_OPENAI_MODEL=gpt-3.5-turbo
TERMINAL_AI_OPENAI_MAX_TOKENS=2000
TERMINAL_AI_OPENAI_TEMPERATURE=0.7
TERMINAL_AI_OPENAI_TOP_P=1.0
TERMINAL_AI_OPENAI_N=1

# API Settings
TERMINAL_AI_OPENAI_BASE_URL=https://api.openai.com/v1
TERMINAL_AI_OPENAI_TIMEOUT=30s
TERMINAL_AI_OPENAI_ORG_ID=

# Stop sequences (comma-separated)
# TERMINAL_AI_OPENAI_STOP=

# ==============================================================================
# Cache Configuration
# ==============================================================================

TERMINAL_AI_CACHE_ENABLED=true
TERMINAL_AI_CACHE_TTL=5m
TERMINAL_AI_CACHE_MAX_SIZE=100
TERMINAL_AI_CACHE_STRATEGY=lru
# Cache directory (defaults to ~/.terminal-ai/cache)
# TERMINAL_AI_CACHE_DIR=${HOME}/.terminal-ai/cache

# ==============================================================================
# UI Configuration
# ==============================================================================

TERMINAL_AI_UI_STREAMING_ENABLED=true
TERMINAL_AI_UI_COLOR_OUTPUT=true
TERMINAL_AI_UI_MARKDOWN_RENDERING=true
TERMINAL_AI_UI_SYNTAX_HIGHLIGHTING=true
TERMINAL_AI_UI_THEME=auto
TERMINAL_AI_UI_SPINNER=dots
# Terminal width (0 for auto-detect)
TERMINAL_AI_UI_WIDTH=0

# ==============================================================================
# Logging Configuration
# ==============================================================================

# Log level: debug, info, warn, error, fatal, panic
TERMINAL_AI_LOGGING_LEVEL=info
# Log format: json, text, pretty
TERMINAL_AI_LOGGING_FORMAT=text
# Log file path (empty for stdout)
TERMINAL_AI_LOGGING_FILE=
# Never log API keys (security feature)
TERMINAL_AI_LOGGING_NO_API=true

# ==============================================================================
# Profile Configuration
# ==============================================================================

# Profile: dev, prod, custom
TERMINAL_AI_PROFILE=prod

# ==============================================================================
# Optional: Alternative AI Providers
# ==============================================================================

# Anthropic API (for Claude models)
# ANTHROPIC_API_KEY=your-anthropic-key-here
# TERMINAL_AI_ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# Azure OpenAI
# TERMINAL_AI_AZURE_ENDPOINT=https://your-resource.openai.azure.com/
# TERMINAL_AI_AZURE_API_KEY=your-azure-key-here
# TERMINAL_AI_AZURE_DEPLOYMENT_NAME=your-deployment-name

# Custom/Local Models
# TERMINAL_AI_CUSTOM_ENDPOINT=http://localhost:8080/v1
# TERMINAL_AI_CUSTOM_API_KEY=optional-key

# ==============================================================================
# Optional: Proxy Settings
# ==============================================================================

# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080
# NO_PROXY=localhost,127.0.0.1

# ==============================================================================
# Optional: Advanced Settings
# ==============================================================================

# Request retry configuration
# TERMINAL_AI_RETRY_MAX_ATTEMPTS=3
# TERMINAL_AI_RETRY_DELAY=1s

# Rate limiting
# TERMINAL_AI_RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Connection pooling
# TERMINAL_AI_MAX_IDLE_CONNS=10
# TERMINAL_AI_MAX_CONNS_PER_HOST=2